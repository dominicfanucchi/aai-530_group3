{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 3 Final Project Technical Notebook\n",
    "\n",
    "Name(s): Dominic Fanucchi, Daniel Grant, Isaack Karanja   \n",
    "Date:    February 26, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to CSV files\n",
    "path_to_files = r'G:/development/USD/aai_530/aai-530_group3/citypulse_traffic_raw_data_surrey_feb_jun_2014/traffic_feb_june/*.csv'\n",
    "\n",
    "# Set the maximum number of rows for the combined subset\n",
    "max_rows = 1000000\n",
    "current_rows = 0\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create an empty DataFrame for the combined subset\n",
    "combined_subset_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file, read its data, and take a random subset\n",
    "for file_path in glob.glob(path_to_files):\n",
    "    # Read CSV file into a DataFrame\n",
    "    file_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Take a subset of the data for EDA (adjust the limit as needed)\n",
    "    file_subset_data = file_data.sample(n=1000, random_state=42)\n",
    "\n",
    "    # Check if adding the current subset exceeds the maximum rows limit\n",
    "    if current_rows + len(file_subset_data) <= max_rows:\n",
    "        # Concatenate the subset from the current file into the overall subset DataFrame\n",
    "        combined_subset_data = pd.concat([combined_subset_data, file_subset_data], ignore_index=True)\n",
    "        current_rows += len(file_subset_data)\n",
    "\n",
    "        # Print the current number of rows after processing each file\n",
    "        # print(f'Rows after processing {file_path}: {current_rows}')\n",
    "    else:\n",
    "        # Break the loop if the limit is reached\n",
    "        break\n",
    "\n",
    "# Print some debugging information\n",
    "print(f'Final rows: {current_rows}')\n",
    "print(f'DataFrame shape: {combined_subset_data.shape}')\n",
    "\n",
    "# Save the combined subset DataFrame to a new CSV file\n",
    "combined_subset_data.to_csv(r'G:/development/USD/aai_530/aai-530_group3/combined_subset_traffic_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_subset_traffic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 rows of the column\n",
    "time = df['TIMESTAMP'].head(10)\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'].str.replace('T', ' '), format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print updated dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot('TIMESTAMP', ['avgMeasuredTime',\t'avgSpeed',\t'extID',\t'medianMeasuredTime',\t'vehicleCount',\t'_id',\t'REPORT_ID'], subplots=True, figsize=(20,15))\n",
    "df.plot('TIMESTAMP', ['avgMeasuredTime', 'avgSpeed', 'medianMeasuredTime', 'vehicleCount'], subplots=True, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_avg = df.groupby(pd.Grouper(key = 'TIMESTAMP', freq='1M')).mean()\n",
    "\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "df_avg = df.groupby(pd.Grouper(key='TIMESTAMP', freq='1D'))[numeric_columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.plot(y=['avgMeasuredTime', 'avgSpeed', 'medianMeasuredTime', 'vehicleCount'], use_index=True, subplots=True, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = pd.plotting.scatter_matrix(df[['avgMeasuredTime', 'avgSpeed', 'medianMeasuredTime', 'vehicleCount']], alpha=0.5,figsize =(10,10))\n",
    "corr = df[['avgMeasuredTime', 'avgSpeed', 'medianMeasuredTime', 'vehicleCount']].corr(method = 'spearman').to_numpy() #nonlinear\n",
    "for i, j in zip(*plt.np.triu_indices_from(axes, k=1)):\n",
    "    axes[i, j].annotate(\"%.3f\" %corr[i,j], (0.8, 0.8), xycoords='axes fraction', ha='center', va='center')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unix'] = df['TIMESTAMP'].apply(lambda x:int(x.timestamp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='TIMESTAMP')\n",
    "df.head(10)\n",
    "# Calculate the time differences between consecutive timestamps\n",
    "time_diff = df['TIMESTAMP'].diff()\n",
    "\n",
    "# Compute the mean time difference\n",
    "average_time_difference = time_diff.mean().total_seconds()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Average time difference: {average_time_difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.DataFrame(df.unix)\n",
    "ys = pd.DataFrame(df.vehicleCount)\n",
    "\n",
    "ph = 5 * 60 #5 minutes\n",
    "ph_index = round(ph/average_time_difference) #ph/data resolution (how many timesteps is our ph?)\n",
    "mu = 0.9\n",
    "\n",
    "#let's limit the number of samples in our model to 5000 just for speed\n",
    "n_s = 50000\n",
    "\n",
    "# Arrays to hold predicted values\n",
    "tp_pred = np.zeros(n_s-1)\n",
    "yp_pred = np.zeros(n_s-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At every iteration of the for loop a new data sample is acquired\n",
    "for i in range(2, n_s+1):# start out with 2 leading datapoints\n",
    "    #get x and y data \"available\" for our prediction\n",
    "    ts_tmp = ts[0:i]\n",
    "    ys_tmp = ys[0:i]\n",
    "    ns = len(ys_tmp)\n",
    "\n",
    "\n",
    "    weights = np.ones(ns)*mu\n",
    "    for k in range(ns):\n",
    "        #adjust weights to be downweighted according to their timestep away from our prediction\n",
    "        weights[k] = weights[k] ** k\n",
    "    weights = np.flip(weights, 0)\n",
    "\n",
    "    #perform linear regression on \"available\" data using the mu-adjusted weights\n",
    "    lm_tmp = LinearRegression()\n",
    "    model_tmp = lm_tmp.fit(ts_tmp, ys_tmp, sample_weight=weights)\n",
    "    \n",
    "    #store model coefficients and intercepts to compute prediction\n",
    "    m_tmp = model_tmp.coef_\n",
    "    q_tmp = model_tmp.intercept_\n",
    "    # print(f'm_tmp: {m_tmp.shape}, q_tmp: {q_tmp.shape}')\n",
    "    #use ph to make the model prediction according to the prediction time\n",
    "    tp = ts.iloc[ns-1,0] + ph\n",
    "    yp = m_tmp * tp + q_tmp\n",
    "\n",
    "    # print(f'yp: {yp.shape}')\n",
    "\n",
    "    tp_pred[i-2] = tp\n",
    "    yp_pred[i-2] = yp[0,0] # resolve deprecation warning: extract the scalarâ£value from the np.array 'yp' before assignment\n",
    "\n",
    "# mu_weight = mu ** n_s\n",
    "# print(mu_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "fig.suptitle('Vehicle Count Prediction', fontsize=22, fontweight='bold')\n",
    "ax.set_title('mu = %g, ph=%g ' %(mu, ph))\n",
    "\n",
    "ax.plot(tp_pred, yp_pred, label='Predicted Value')\n",
    "ax.plot(ts.iloc[0:n_s,0], ys.iloc[0:n_s,0], label='Traffic data')\n",
    "\n",
    "ax.set_xlabel('time (unix)')\n",
    "ax.set_ylabel('count')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot first 500 data points/predictions\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "fig.suptitle('Vehicle Count Prediction (First 200)', fontsize=22, fontweight='bold')\n",
    "ax.set_title('mu = %g, ph=%g ' %(mu, ph))\n",
    "\n",
    "ax.plot(tp_pred[0:500], yp_pred[0:500], label='Predicted Value')\n",
    "ax.plot(ts.iloc[0:500,0], ys.iloc[0:500,0], label='Traffic data')\n",
    "\n",
    "\n",
    "ax.set_xlabel('time (unix)')\n",
    "ax.set_ylabel('count')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot last 500 data points/predictions\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "fig.suptitle('Vehicle Count Prediction (Last 500)', fontsize=22, fontweight='bold')\n",
    "ax.set_title('mu = %g, ph=%g ' %(mu, ph))\n",
    "\n",
    "ax.plot(tp_pred[-500:], yp_pred[-500:], label='Predicted Value')\n",
    "ax.plot(ts.iloc[n_s-500:n_s,0], ys.iloc[n_s-500:n_s,0], label='Traffic data')\n",
    "\n",
    "\n",
    "ax.set_xlabel('time (unix)')\n",
    "ax.set_ylabel('count')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MSE of predictions\n",
    "print(\"MSE is\", mse(ys['vehicleCount'][ph_index:50000+ph_index-1],yp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewriting Linear Regression Model with new data subset.Trying to make improvements and save off prediction dataset to be used in Tableau dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing huggingface package\n",
    "from datasets import load_dataset, Value\n",
    "#suppress scientific notation in pandas\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"dgrant6/down_sampled_file_traffic_dataset2\",\n",
    "    data_files={\n",
    "        \"test\": \"test-00000-of-00001.parquet\",\n",
    "        \"train\": \"train-00000-of-00001.parquet\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# new data files, but having caching issues and cannot fully load the dataset\n",
    "# dataset = load_dataset(\n",
    "#     \"mugithi/down_sampled_file_traffic_dataset\", \n",
    "#     data_files={\n",
    "#         \"train\": \"data/train-00000-of-00002.parquet\", \n",
    "#         \"test\": \"data/test-00000-of-00001.parquet\",\n",
    "#         \"train_2\": \"data/train-00001-of-00002.parquet\"\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the huggingface parquet files into Pandas DataFrames\n",
    "df = dataset['train'].to_pandas()\n",
    "df_test = dataset['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see everything loaded in correctly. The data has already been cleaned, and EDA has been done in a seperate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(\"*\" * 80)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scrolling through the dataset on huggingface, the TIMESTAMP column shows readings every 5 minutes. This should simplify some aspects of our time series analysis.\n",
    "- Convert TIMESTAMP and unix to dataetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "df_test['TIMESTAMP'] = pd.to_datetime(df_test['TIMESTAMP'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = df.describe(include='all')\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We not have any missing data, which we should expect, since we are working with a cleaned dataset. Now, we can move on visualizing our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot('TIMESTAMP', ['avgSpeed'], figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'unix' and 'junction' and calculate the mean of 'avgSpeed' for each junction and timestamp\n",
    "grouped_data = df.groupby(['unix', 'junction'])['avgSpeed'].mean().reset_index()\n",
    "\n",
    "# Plot average speed for each junction\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# Iterate over unique junctions and plot each one\n",
    "for junction in grouped_data['junction'].unique():\n",
    "    junction_data = grouped_data[grouped_data['junction'] == junction]\n",
    "    plt.plot(junction_data['unix'], junction_data['avgSpeed'], label=f'Junction {junction}')\n",
    "\n",
    "# Set labels and legend\n",
    "plt.xlabel('Unix Timestamp')\n",
    "plt.ylabel('Average Speed')\n",
    "plt.title('Average Speed Over Time for Each Junction')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is extremely noise and cannot discerne any useful information from it. I will be doing aggregate time intervals as well as subplots so help reduce some of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique junctions\n",
    "unique_junctions = df['junction'].unique()\n",
    "num_junctions = len(unique_junctions)\n",
    "# print(num_junctions)\n",
    "\n",
    "# Determine the number of subplots (let's say 5 subplots for demonstration)\n",
    "num_subplots = min(num_junctions, 30)\n",
    "# print(num_subplots)\n",
    "\n",
    "# Calculate the number of junctions per subplot\n",
    "junctions_per_subplot = int(np.ceil(num_junctions / num_subplots))\n",
    "# print(junctions_per_subplot)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_subplots, 1, figsize=(20, 5 * num_subplots), sharex=True)\n",
    "\n",
    "# Iterate over subplots and plot each set of junctions\n",
    "for i in range(num_subplots):\n",
    "    start_idx = i * junctions_per_subplot\n",
    "    end_idx = (i + 1) * junctions_per_subplot\n",
    "\n",
    "    # Plot for the current set of junctions\n",
    "    for junction in unique_junctions[start_idx:end_idx]:\n",
    "        junction_data = df[df['junction'] == junction]\n",
    "        # Group by 'Date_no' and calculate the mean of 'avgSpeed' for each day\n",
    "        daily_avg_data = junction_data.groupby('Date_no')['avgSpeed'].mean().reset_index()\n",
    "        axes[i].plot(daily_avg_data['Date_no'], daily_avg_data['avgSpeed'], label=f'Junction {junction}')\n",
    "\n",
    "    axes[i].set_ylabel('Average Speed')\n",
    "    axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Legends on the right side\n",
    "\n",
    "    # Explicitly set x tick positions for each day of the month\n",
    "    axes[i].set_xticks(junction_data['Date_no'].unique())\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Set common x-axis label and title\n",
    "plt.xlabel('Unix Timestamp')\n",
    "plt.suptitle('Average Speed Over Time for Each Set of Junctions (Daily Average)')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.95, 0.97])  # Adjust subplot layout\n",
    "plt.savefig('images/avgSpeed_each_day_for_each_junction.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable for training\n",
    "X_train = df[['vehicleCount', 'Year', 'Month', 'Date_no', 'Hour', 'Day', 'unix', 'junction']]\n",
    "X_train = pd.get_dummies(X_train, columns=['Day'], drop_first=True) # one-hot encode 'Day' column\n",
    "\n",
    "y_train = df['avgSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable for testing\n",
    "X_test = df_test[['vehicleCount', 'Year', 'Month', 'Date_no', 'Hour', 'Day', 'unix', 'junction']]\n",
    "\n",
    "# One-hot encode the 'Day' column for test data\n",
    "X_test = pd.get_dummies(X_test, columns=['Day'], drop_first=True)\n",
    "\n",
    "y_test = df_test['avgSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "mse_value = mse(y_test, predictions)\n",
    "print(f'Mean Squared Error on Test Data: {mse_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_junctions = X_test['junction'].unique()[:5]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(30, 25), sharex=True)\n",
    "\n",
    "for i, junction in enumerate(selected_junctions):\n",
    "    # Filter data for the specific junction\n",
    "    junction_data = X_test[X_test['junction'] == junction]\n",
    "    \n",
    "    # Make predictions for the junction\n",
    "    junction_predictions = model.predict(junction_data)\n",
    "    \n",
    "    # Plot actual vs predicted values\n",
    "    axes[i].plot(junction_data['unix'], y_test[junction_data.index], label='Actual', marker='o')\n",
    "    axes[i].plot(junction_data['unix'], junction_predictions, label='Predicted', marker='o')\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    axes[i].set_title(f'Junction {junction} - Actual vs Predicted')\n",
    "    axes[i].set_ylabel('avgSpeed')\n",
    "    axes[i].legend()\n",
    "\n",
    "axes[-1].set_xlabel('Timestamp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('images/5_junction_avgSpeed_prediction_vs_actual.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method for linear regression, very similar to lab assignment\n",
    "\n",
    "# Select features and target variable for training\n",
    "# X_train = df[['vehicleCount', 'Year', 'Month', 'Date_no', 'Hour', 'Day', 'unix', 'junction']]\n",
    "# X_train = pd.get_dummies(X_train, columns=['Day'], drop_first=True) # one-hot encode 'Day' column\n",
    "\n",
    "X_train = df[['vehicleCount', 'unix', 'junction']]\n",
    "y_train = df['avgSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = 300\n",
    "ph_index = round(ph/60)\n",
    "mu = 0.9\n",
    "\n",
    "n_s = 1000\n",
    "\n",
    "#arrays to hold predicted values\n",
    "tp_pred = np.zeros(n_s-31)\n",
    "yp_pred = np.zeros(n_s-31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in range(32, n_s + 1):\n",
    "    ts_tmp = X_train.iloc[30:i, :]\n",
    "\n",
    "    # Scale the features\n",
    "    ts_tmp_scaled = scaler.fit_transform(ts_tmp)\n",
    "\n",
    "    ys_tmp = y_train.iloc[30+ph_index-1:ph_index-1+i]\n",
    "    ns = len(ys_tmp)\n",
    "\n",
    "    weights = np.ones(ns) * mu\n",
    "\n",
    "    for k in range(ns):\n",
    "        weights[k] = weights[k] ** k\n",
    "    weights = np.flip(weights, 0)\n",
    "\n",
    "    lm_tmp = LinearRegression()\n",
    "    model_tmp = lm_tmp.fit(ts_tmp_scaled, ys_tmp, sample_weight=weights)\n",
    "\n",
    "    m_tmp = model_tmp.coef_\n",
    "    q_tmp = model_tmp.intercept_\n",
    "\n",
    "    # print(f'Coefficients: {m_tmp}, Intercept: {q_tmp}')\n",
    "\n",
    "    vehicleCount = X_train.iloc[i, 0]\n",
    "    unix = X_train.iloc[i, 1]\n",
    "    junction = X_train.iloc[i, 2]\n",
    "\n",
    "    yp = m_tmp[0] * vehicleCount + m_tmp[1] * unix + m_tmp[2] * junction + q_tmp\n",
    "\n",
    "    tp_pred[i-32] = unix + ph\n",
    "    yp_pred[i-32] = yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "fig.suptitle('Average Speed Prediction - First 200 Points', fontsize=22, fontweight='bold')\n",
    "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
    "ax.plot(tp_pred[:200], yp_pred[:200], label='Predicted Speed')\n",
    "ax.plot(X_train.iloc[30:230, 1], y_train.iloc[30:230], label='avgSpeed data')\n",
    "# ax.set_xlabel('')\n",
    "# ax.set_ylabel('')\n",
    "ax.legend()\n",
    "\n",
    "# Print coefficients\n",
    "print(f'Coefficients: {m_tmp}, Intercept: {q_tmp}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and target variable\n",
    "X_train = df[['vehicleCount', 'unix', 'junction']]\n",
    "y_train = df['avgSpeed']\n",
    "\n",
    "# Select relevant features and target variable\n",
    "X_test = df_test[['vehicleCount', 'unix', 'junction']]\n",
    "y_test = df_test['avgSpeed']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# evaluate model\n",
    "mse = mse(y_test, predictions)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "# randomly select a junction from the test set\n",
    "random_junction = np.random.choice(X_test['junction'].unique())\n",
    "\n",
    "# filter data for the random junction\n",
    "random_junction_data = X_test[X_test['junction'] == random_junction]\n",
    "random_junction_predictions = model.predict(scaler.transform(random_junction_data[['vehicleCount', 'unix', 'junction']]))\n",
    "\n",
    "\n",
    "# print(f'Predictions for Random Junction ({random_junction}): {random_junction_predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Assuming you have already trained the model and made predictions for a random junction\n",
    "# random_junction_data and random_junction_predictions are assumed to be available\n",
    "\n",
    "# Plot actual vs predicted values for the random junction\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(random_junction_data['unix'], y_test[random_junction_data.index], label='Actual', marker='o')\n",
    "plt.plot(random_junction_data['unix'], random_junction_predictions, label='Predicted', marker='o')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.title(f'Actual vs Predicted Values for Random Junction ({random_junction})')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('avgSpeed')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with actual and predicted values\n",
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('data/predictions.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.describe(include='all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
